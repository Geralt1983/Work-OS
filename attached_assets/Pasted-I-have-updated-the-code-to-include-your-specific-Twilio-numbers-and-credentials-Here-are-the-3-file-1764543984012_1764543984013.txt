I have updated the code to include your specific Twilio numbers and credentials.
Here are the 3 files you need to update to turn on the "Wife Notification" system.
1. Create server/notification-service.ts
This is the new file that handles sending the texts. I have pre-filled your numbers and keys.
import Twilio from "twilio";

// Configuration
const FROM_PHONE = "+13047798392"; // Your Twilio Number
const TO_PHONE = "+13363208199";   // Wife's Number

// Credentials
const accountSid = process.env.TWILIO_SID || "AC0d12c8bd12e79578ed629e2383792d74";
const authToken = process.env.TWILIO_TOKEN || "f63e4695c456880cdbbb84da97176c11";

const client = new Twilio(accountSid, authToken);

export async function sendWifeAlert(percent: number, movesCount: number) {
  console.log(`[Notification] Checking alert for ${percent}%...`);

  const messages: Record<number, string> = {
    25: `ðŸš€ Jeremy just hit 25% of his daily goal! (${movesCount} moves down)`,
    50: `ðŸ”¥ Halfway there! Jeremy is at 50% for the day. Send coffee â˜•`,
    75: `ðŸ˜¤ Crushing it. 75% done. Almost time for dinner.`,
    100: `âœ… BOOM. Jeremy finished 100% of his work day. High five him! ðŸ™Œ`
  };

  const body = messages[percent];
  if (!body) return;

  try {
    await client.messages.create({
      body,
      from: FROM_PHONE,
      to: TO_PHONE,
    });
    console.log(`âœ… SMS sent to wife: ${percent}% milestone`);
  } catch (error) {
    console.error("âŒ Failed to send SMS:", error);
  }
}

2. Update shared/schema.ts
We need to add the notificationsSent field to the dailyLog table so we don't spam her if you click a task twice.
import { pgTable, text, timestamp, jsonb, integer, serial, index } from "drizzle-orm/pg-core"; // Added index
import { createInsertSchema } from "drizzle-zod";
import { z } from "zod";

// ============ CORE ENTITIES ============

// Clients: First-class entity for tracking work relationships
export const clients = pgTable("clients", {
  id: serial("id").primaryKey(),
  name: text("name").notNull().unique(),
  type: text("type").notNull().default("client"), // 'client' | 'internal'
  color: text("color"), // hex color for UI
  isActive: integer("is_active").notNull().default(1), // 1 = active, 0 = archived
  createdAt: timestamp("created_at").defaultNow().notNull(),
});

// Moves: The core work unit (20-minute tasks)
export const moves = pgTable("moves", {
  id: serial("id").primaryKey(),
  clientId: integer("client_id").references(() => clients.id),
  title: text("title").notNull(),
  description: text("description"),
  status: text("status").notNull().default("backlog"), // 'active' | 'queued' | 'backlog' | 'done'
  effortEstimate: integer("effort_estimate").default(2), // 1=quick, 2=standard, 3=chunky, 4=draining
  effortActual: integer("effort_actual"), // filled after completion
  drainType: text("drain_type"), // 'deep' | 'comms' | 'admin' | 'creative' | 'easy' | null
  sortOrder: integer("sort_order").default(0), // for manual ordering within status
  createdAt: timestamp("created_at").defaultNow().notNull(),
  completedAt: timestamp("completed_at"),
}, (table) => ({
  statusIdx: index("status_idx").on(table.status),
  clientIdIdx: index("client_id_idx").on(table.clientId),
  clientStatusIdx: index("client_status_idx").on(table.clientId, table.status),
}));

export const sessions = pgTable("sessions", {
  id: text("id").primaryKey(),
  createdAt: timestamp("created_at").defaultNow().notNull(),
  lastActiveAt: timestamp("last_active_at").defaultNow().notNull(),
});

export const messages = pgTable("messages", {
  id: text("id").primaryKey(),
  sessionId: text("session_id").notNull().references(() => sessions.id),
  role: text("role").notNull(),
  content: text("content").notNull(),
  timestamp: timestamp("timestamp").defaultNow().notNull(),
  taskCard: jsonb("task_card"),
});

export const clientMemory = pgTable("client_memory", {
  id: text("id").primaryKey(),
  clientName: text("client_name").notNull().unique(),
  tier: text("tier").default("active"),
  lastMoveId: text("last_move_id"),
  lastMoveDescription: text("last_move_description"),
  lastMoveAt: timestamp("last_move_at"),
  totalMoves: integer("total_moves").default(0),
  staleDays: integer("stale_days").default(0),
  notes: text("notes"),
  sentiment: text("sentiment").default("neutral"),
  importance: text("importance").default("medium"),
  preferredWorkTime: text("preferred_work_time"),
  avoidanceScore: integer("avoidance_score").default(0),
  createdAt: timestamp("created_at").defaultNow().notNull(),
  updatedAt: timestamp("updated_at").defaultNow().notNull(),
});

export const dailyLog = pgTable("daily_log", {
  id: text("id").primaryKey(),
  date: text("date").notNull(),
  completedMoves: jsonb("completed_moves").default([]),
  clientsTouched: jsonb("clients_touched").default([]),
  clientsSkipped: jsonb("clients_skipped").default([]),
  summary: text("summary"),
  backlogMovesCount: integer("backlog_moves_count").default(0),
  nonBacklogMovesCount: integer("non_backlog_moves_count").default(0),
  notificationsSent: jsonb("notifications_sent").default([]), // NEW FIELD FOR SMS TRACKING
  createdAt: timestamp("created_at").defaultNow().notNull(),
});

// Learning memory: tracks behavioral patterns over time
export const userPatterns = pgTable("user_patterns", {
  id: text("id").primaryKey(),
  patternType: text("pattern_type").notNull(),
  patternKey: text("pattern_key").notNull(),
  patternValue: jsonb("pattern_value"),
  confidence: integer("confidence").default(1),
  lastObserved: timestamp("last_observed").defaultNow().notNull(),
  createdAt: timestamp("created_at").defaultNow().notNull(),
});

export const taskSignals = pgTable("task_signals", {
  id: text("id").primaryKey(),
  taskId: text("task_id"),
  taskName: text("task_name"),
  clientName: text("client_name"),
  signalType: text("signal_type").notNull(),
  context: text("context"),
  hourOfDay: integer("hour_of_day"),
  dayOfWeek: integer("day_of_week"),
  timeWindowMinutes: integer("time_window_minutes"),
  energyLevel: text("energy_level"),
  createdAt: timestamp("created_at").defaultNow().notNull(),
});

export const backlogEntries = pgTable("backlog_entries", {
  id: text("id").primaryKey(),
  taskId: text("task_id").notNull(),
  taskName: text("task_name").notNull(),
  clientName: text("client_name").notNull(),
  enteredAt: timestamp("entered_at").defaultNow().notNull(),
  promotedAt: timestamp("promoted_at"),
  daysInBacklog: integer("days_in_backlog").default(0),
  autoPromoted: integer("auto_promoted").default(0),
});

export const taskCardSchema = z.object({
  title: z.string(),
  taskId: z.string(),
  status: z.string(),
  dueDate: z.string().optional(),
});

// ============ INSERT SCHEMAS ============

export const insertClientSchema = createInsertSchema(clients).omit({ id: true, createdAt: true });
export const insertMoveSchema = createInsertSchema(moves).omit({ id: true, createdAt: true, completedAt: true });
export const insertSessionSchema = createInsertSchema(sessions).omit({ id: true, createdAt: true, lastActiveAt: true });
export const insertMessageSchema = createInsertSchema(messages).omit({ id: true, timestamp: true });
export const insertClientMemorySchema = createInsertSchema(clientMemory).omit({ id: true, createdAt: true, updatedAt: true });
export const insertDailyLogSchema = createInsertSchema(dailyLog).omit({ id: true, createdAt: true });
export const insertUserPatternSchema = createInsertSchema(userPatterns).omit({ id: true, createdAt: true, lastObserved: true });
export const insertTaskSignalSchema = createInsertSchema(taskSignals).omit({ id: true, createdAt: true });
export const insertBacklogEntrySchema = createInsertSchema(backlogEntries).omit({ id: true });

// ============ TYPES ============

export type Client = typeof clients.$inferSelect;
export type InsertClient = z.infer<typeof insertClientSchema>;
export type Move = typeof moves.$inferSelect;
export type InsertMove = z.infer<typeof insertMoveSchema>;
export type Session = typeof sessions.$inferSelect;
export type InsertSession = z.infer<typeof insertSessionSchema>;
export type Message = typeof messages.$inferSelect;
export type InsertMessage = z.infer<typeof insertMessageSchema>;
export type ClientMemory = typeof clientMemory.$inferSelect;
export type InsertClientMemory = z.infer<typeof insertClientMemorySchema>;
export type DailyLog = typeof dailyLog.$inferSelect;
export type InsertDailyLog = z.infer<typeof insertDailyLogSchema>;
export type UserPattern = typeof userPatterns.$inferSelect;
export type InsertUserPattern = z.infer<typeof insertUserPatternSchema>;
export type TaskSignal = typeof taskSignals.$inferSelect;
export type InsertTaskSignal = z.infer<typeof insertTaskSignalSchema>;
export type BacklogEntry = typeof backlogEntries.$inferSelect;
export type InsertBacklogEntry = z.infer<typeof insertBacklogEntrySchema>;
export type TaskCard = z.infer<typeof taskCardSchema>;

// ============ STATUS & EFFORT CONSTANTS ============

export const MOVE_STATUSES = ["active", "queued", "backlog", "done"] as const;
export type MoveStatus = typeof MOVE_STATUSES[number];

export const EFFORT_LEVELS = [
  { value: 1, label: "Quick", description: "< 10 min" },
  { value: 2, label: "Standard", description: "~20 min" },
  { value: 3, label: "Chunky", description: "30-45 min" },
  { value: 4, label: "Draining", description: "45+ min or high effort" },
] as const;

export const DRAIN_TYPES = ["deep", "comms", "admin", "creative", "easy"] as const;
export type DrainType = typeof DRAIN_TYPES[number];

export const DRAIN_TYPE_LABELS: Record<DrainType, { label: string; description: string }> = {
  deep: { label: "Deep Work", description: "Focus-intensive building, research, complex problems" },
  comms: { label: "Comms", description: "Meetings, emails, calls, discussions" },
  admin: { label: "Admin", description: "Invoices, scheduling, updates, paperwork" },
  creative: { label: "Creative", description: "Strategic thinking, proposals, design work" },
  easy: { label: "Easy", description: "Low-effort quick wins, routine tasks" },
} as const;

export const LEGACY_DRAIN_TYPE_MAP: Record<string, DrainType> = {
  mental: "deep",
  emotional: "comms",
  physical: "admin",
};

export function normalizeDrainType(drainType: string | null | undefined): DrainType | null {
  if (!drainType) return null;
  if (DRAIN_TYPES.includes(drainType as DrainType)) return drainType as DrainType;
  return LEGACY_DRAIN_TYPE_MAP[drainType] || null;
}

export const CLIENT_TYPES = ["client", "internal"] as const;
export type ClientType = typeof CLIENT_TYPES[number];

// ============ LEARNING SIGNAL TYPES ============

export const SIGNAL_TYPES = [
  "deferred",           // pushed to later
  "avoided",            // explicitly skipped
  "completed_fast",     // done quickly
  "struggled",          // took effort/multiple attempts
  "excited",            // user showed enthusiasm
  "anxiety",            // user felt anxious about task
  "starting_difficulty", // trouble getting started
  "needs_breakdown",    // task was too big, needed splitting
  "energized",          // task gave energy/motivation
  "drained",            // task was draining
] as const;
export type SignalType = typeof SIGNAL_TYPES[number];

export const SIGNAL_TYPE_LABELS: Record<SignalType, { label: string; description: string }> = {
  deferred: { label: "Deferred", description: "Pushed to later" },
  avoided: { label: "Avoided", description: "Explicitly skipped" },
  completed_fast: { label: "Completed Fast", description: "Done quickly" },
  struggled: { label: "Struggled", description: "Took effort or multiple attempts" },
  excited: { label: "Excited", description: "Showed enthusiasm" },
  anxiety: { label: "Anxiety", description: "Felt anxious about this task" },
  starting_difficulty: { label: "Starting Difficulty", description: "Had trouble getting started" },
  needs_breakdown: { label: "Needs Breakdown", description: "Task was too big, needed splitting" },
  energized: { label: "Energized", description: "Task gave energy and motivation" },
  drained: { label: "Drained", description: "Task was energy-draining" },
} as const;

export const ENERGY_LEVELS = ["high", "medium", "low"] as const;
export type EnergyLevel = typeof ENERGY_LEVELS[number];

3. Update server/routes.ts
We need to trigger the alert service when a move is completed.
import type { Express } from "express";
import { createServer, type Server } from "http";
import { storage, getLocalDateString } from "./storage";
import { processChat } from "./openai-service";
import { runTriage, runTriageWithAutoRemediation } from "./pipeline-tools";
import { z } from "zod";
import { insertClientSchema, insertMoveSchema, MOVE_STATUSES, type MoveStatus } from "@shared/schema";
import { sendWifeAlert } from "./notification-service"; // Import notification service

const sendMessageSchema = z.object({
  sessionId: z.string().optional().nullable(),
  message: z.string().min(1),
  imageUrl: z.string().optional().nullable(),
  imageBase64: z.string().optional().nullable(),
  imagesBase64: z.array(z.string()).optional().nullable(),
});

const updateMoveSchema = z.object({
  title: z.string().optional(),
  description: z.string().nullable().optional(),
  status: z.enum(MOVE_STATUSES).optional(),
  clientId: z.number().nullable().optional(),
  effortEstimate: z.number().optional(),
  effortActual: z.number().nullable().optional(),
  drainType: z.string().nullable().optional(),
  sortOrder: z.number().optional(),
});

const updateClientSchema = z.object({
  name: z.string().optional(),
  type: z.string().optional(),
  color: z.string().nullable().optional(),
  isActive: z.number().optional(),
});

export async function registerRoutes(app: Express): Promise<Server> {

  app.post("/api/sessions", async (req, res) => {
    try {
      const session = await storage.createSession({});
      res.json(session);
    } catch (error) {
      console.error("Error creating session:", error);
      res.status(500).json({ error: "Failed to create session" });
    }
  });

  app.get("/api/sessions/:id/messages", async (req, res) => {
    try {
      const messages = await storage.getMessages(req.params.id);
      res.json(messages);
    } catch (error) {
      console.error("Error fetching messages:", error);
      res.status(500).json({ error: "Failed to fetch messages" });
    }
  });

  app.post("/api/chat", async (req, res) => {
    try {
      const { sessionId: providedSessionId, message, imageUrl, imageBase64, imagesBase64 } = sendMessageSchema.parse(req.body);

      let sessionId = providedSessionId;
      if (!sessionId) {
        const session = await storage.createSession({});
        sessionId = session.id;
      }

      const allImages = imagesBase64 || (imageBase64 ? [imageBase64] : undefined);
      const hasImages = allImages && allImages.length > 0;

      const userMessage = await storage.createMessage({
        sessionId,
        role: "user",
        content: hasImages ? `[${allImages.length > 1 ? 'Images' : 'Image'} attached]\n${message}` : message,
      });

      const conversationHistory = await storage.getSessionMessages(sessionId, 20);

      const { content, taskCard } = await processChat(
        conversationHistory, 
        imageUrl || undefined, 
        allImages
      );

      const assistantMessage = await storage.createMessage({
        sessionId,
        role: "assistant",
        content,
        taskCard,
      });

      await storage.updateSessionActivity(sessionId);

      res.json({
        sessionId,
        userMessage,
        assistantMessage,
      });
    } catch (error) {
      console.error("Error processing chat:", error);
      res.status(500).json({ 
        error: error instanceof Error ? error.message : "Failed to process chat" 
      });
    }
  });

  app.post("/api/briefing", async (req, res) => {
    try {
      const { sessionId } = req.body;
      if (!sessionId) return res.status(400).json({ error: "Session ID required" });
      
      // We need to import this dynamically or move it to a shared location to avoid circular deps
      // For now assuming it's available via openai-service
      const { generateMorningBriefing } = await import("./openai-service");
      const briefing = await generateMorningBriefing(sessionId);
      res.json({ content: briefing });
    } catch (error) {
      console.error("Briefing error:", error);
      res.status(500).json({ error: "Failed to generate briefing" });
    }
  });

  app.get("/api/health", async (req, res) => {
    res.json({
      status: "ok",
    });
  });

  // Metrics endpoints
  app.get("/api/metrics/today", async (req, res) => {
    try {
      const metrics = await storage.getTodayMetrics();
      res.json(metrics);
    } catch (error) {
      console.error("Error fetching today's metrics:", error);
      res.status(500).json({ error: "Failed to fetch metrics" });
    }
  });

  app.get("/api/metrics/weekly", async (req, res) => {
    try {
      const metrics = await storage.getWeeklyMetrics();
      res.json(metrics);
    } catch (error) {
      console.error("Error fetching weekly metrics:", error);
      res.status(500).json({ error: "Failed to fetch weekly metrics" });
    }
  });

  app.get("/api/metrics/clients", async (req, res) => {
    try {
      const metrics = await storage.getClientMetrics();
      res.json(metrics);
    } catch (error) {
      console.error("Error fetching client metrics:", error);
      res.status(500).json({ error: "Failed to fetch client metrics" });
    }
  });

  app.get("/api/metrics/drain-types", async (req, res) => {
    try {
      const daysBack = req.query.days ? parseInt(req.query.days as string) : 30;
      const metrics = await storage.getDrainTypeMetrics(daysBack);
      res.json(metrics);
    } catch (error) {
      console.error("Error fetching drain type metrics:", error);
      res.status(500).json({ error: "Failed to fetch drain type metrics" });
    }
  });

  app.get("/api/metrics/productivity", async (req, res) => {
    try {
      const metrics = await storage.getProductivityByHour();
      res.json(metrics);
    } catch (error) {
      console.error("Error fetching productivity metrics:", error);
      res.status(500).json({ error: "Failed to fetch productivity metrics" });
    }
  });

  app.get("/api/metrics/backlog-health", async (req, res) => {
    try {
      const health = await storage.getBacklogHealth();
      res.json(health);
    } catch (error) {
      console.error("Error fetching backlog health:", error);
      res.status(500).json({ error: "Failed to fetch backlog health" });
    }
  });

  app.get("/api/metrics/avoided-tasks", async (req, res) => {
    try {
      const daysBack = req.query.days ? parseInt(req.query.days as string) : 14;
      const tasks = await storage.getAvoidedTasks(daysBack);
      res.json(tasks);
    } catch (error) {
      console.error("Error fetching avoided tasks:", error);
      res.status(500).json({ error: "Failed to fetch avoided tasks" });
    }
  });

  app.get("/api/metrics/patterns", async (req, res) => {
    try {
      const patternType = req.query.type as string | undefined;
      const patterns = await storage.getPatterns(patternType);
      res.json(patterns);
    } catch (error) {
      console.error("Error fetching patterns:", error);
      res.status(500).json({ error: "Failed to fetch patterns" });
    }
  });

  const sentimentSchema = z.object({
    sentiment: z.enum(["positive", "neutral", "negative", "complicated"]),
  });

  app.patch("/api/client-memory/:clientName/sentiment", async (req, res) => {
    try {
      const clientName = decodeURIComponent(req.params.clientName).toLowerCase().trim();
      const parseResult = sentimentSchema.safeParse(req.body);
      if (!parseResult.success) {
        res.status(400).json({ error: "Invalid sentiment value", details: parseResult.error.errors });
        return;
      }
      const { sentiment } = parseResult.data;
      const updated = await storage.updateClientSentiment(clientName, sentiment);
      if (!updated) {
        res.status(404).json({ error: "Client not found" });
        return;
      }
      res.json(updated);
    } catch (error) {
      console.error("Error updating client sentiment:", error);
      res.status(500).json({ error: "Failed to update client sentiment" });
    }
  });

  const importanceSchema = z.object({
    importance: z.enum(["high", "medium", "low"]),
  });

  app.patch("/api/client-memory/:clientName/importance", async (req, res) => {
    try {
      const clientName = decodeURIComponent(req.params.clientName).toLowerCase().trim();
      const parseResult = importanceSchema.safeParse(req.body);
      if (!parseResult.success) {
        res.status(400).json({ error: "Invalid importance value", details: parseResult.error.errors });
        return;
      }
      const { importance } = parseResult.data;
      const updated = await storage.updateClientImportance(clientName, importance);
      if (!updated) {
        res.status(404).json({ error: "Client not found" });
        return;
      }
      res.json(updated);
    } catch (error) {
      console.error("Error updating client importance:", error);
      res.status(500).json({ error: "Failed to update client importance" });
    }
  });

  // ============ CLIENTS API ============

  app.get("/api/clients", async (req, res) => {
    try {
      const clients = await storage.getAllClientsEntity();
      res.json(clients);
    } catch (error) {
      console.error("Error fetching clients:", error);
      res.status(500).json({ error: "Failed to fetch clients" });
    }
  });

  app.post("/api/clients", async (req, res) => {
    try {
      const data = insertClientSchema.parse(req.body);
      const client = await storage.createClient(data);
      res.status(201).json(client);
    } catch (error) {
      console.error("Error creating client:", error);
      if (error instanceof z.ZodError) {
        res.status(400).json({ error: "Invalid client data", details: error.errors });
      } else {
        res.status(500).json({ error: "Failed to create client" });
      }
    }
  });

  app.get("/api/clients/:id", async (req, res) => {
    try {
      const id = parseInt(req.params.id);
      const client = await storage.getClient(id);
      if (!client) {
        res.status(404).json({ error: "Client not found" });
        return;
      }
      res.json(client);
    } catch (error) {
      console.error("Error fetching client:", error);
      res.status(500).json({ error: "Failed to fetch client" });
    }
  });

  app.patch("/api/clients/:id", async (req, res) => {
    try {
      const id = parseInt(req.params.id);
      const updates = updateClientSchema.parse(req.body);
      const client = await storage.updateClient(id, updates);
      if (!client) {
        res.status(404).json({ error: "Client not found" });
        return;
      }
      res.json(client);
    } catch (error) {
      console.error("Error updating client:", error);
      if (error instanceof z.ZodError) {
        res.status(400).json({ error: "Invalid update data", details: error.errors });
      } else {
        res.status(500).json({ error: "Failed to update client" });
      }
    }
  });

  app.delete("/api/clients/:id", async (req, res) => {
    try {
      const id = parseInt(req.params.id);
      await storage.archiveClient(id);
      res.status(204).send();
    } catch (error) {
      console.error("Error archiving client:", error);
      res.status(500).json({ error: "Failed to archive client" });
    }
  });

  // ============ MOVES API ============

  app.get("/api/moves", async (req, res) => {
    try {
      const status = req.query.status as MoveStatus | undefined;
      const clientId = req.query.clientId ? parseInt(req.query.clientId as string) : undefined;
      const includeCompleted = req.query.includeCompleted === "true";
      
      const moves = await storage.getAllMoves({ status, clientId, includeCompleted });
      res.json(moves);
    } catch (error) {
      console.error("Error fetching moves:", error);
      res.status(500).json({ error: "Failed to fetch moves" });
    }
  });

  app.post("/api/moves", async (req, res) => {
    try {
      const data = insertMoveSchema.parse(req.body);
      const move = await storage.createMove(data);
      res.status(201).json(move);
    } catch (error) {
      console.error("Error creating move:", error);
      if (error instanceof z.ZodError) {
        res.status(400).json({ error: "Invalid move data", details: error.errors });
      } else {
        res.status(500).json({ error: "Failed to create move" });
      }
    }
  });

  app.get("/api/moves/:id", async (req, res) => {
    try {
      const id = parseInt(req.params.id);
      const move = await storage.getMove(id);
      if (!move) {
        res.status(404).json({ error: "Move not found" });
        return;
      }
      res.json(move);
    } catch (error) {
      console.error("Error fetching move:", error);
      res.status(500).json({ error: "Failed to fetch move" });
    }
  });

  app.patch("/api/moves/:id", async (req, res) => {
    try {
      const id = parseInt(req.params.id);
      const updates = updateMoveSchema.parse(req.body);
      
      // Get old state to check for transitions (like un-completing)
      const oldMove = await storage.getMove(id);
      
      const move = await storage.updateMove(id, updates);
      
      if (!move) {
        res.status(404).json({ error: "Move not found" });
        return;
      }

      // FIX: If we just "Undid" a completion (Done -> Active/Queued/Backlog)
      if (oldMove?.status === 'done' && updates.status && updates.status !== 'done') {
         const today = getLocalDateString();
         await storage.removeCompletedMoves(today, [id.toString()]);
      }

      res.json(move);
    } catch (error) {
      console.error("Error updating move:", error);
      if (error instanceof z.ZodError) {
        res.status(400).json({ error: "Invalid update data", details: error.errors });
      } else {
        res.status(500).json({ error: "Failed to update move" });
      }
    }
  });

  app.post("/api/moves/:id/complete", async (req, res) => {
    try {
      const id = parseInt(req.params.id);
      const effortActual = req.body.effortActual ? parseInt(req.body.effortActual) : undefined;
      const move = await storage.completeMove(id, effortActual);
      if (!move) {
        res.status(404).json({ error: "Move not found" });
        return;
      }
      
      // Log completion for ALL moves (even without client)
      let clientName = "No Client";
      if (move.clientId) {
        const client = await storage.getClient(move.clientId);
        if (client) {
          clientName = client.name;
          // Sync to AI Memory
          await storage.updateClientMove(client.name, move.id.toString(), move.title);
        }
      }
      
      const today = getLocalDateString();
      await storage.addCompletedMove(today, {
        moveId: move.id.toString(),
        description: move.title,
        clientName: clientName,
        at: new Date().toISOString(),
        source: "moves-ui",
      });

      // === WIFE NOTIFICATION TRIGGER ===
      // Get fresh metrics to see where we stand
      const metrics = await storage.getTodayMetrics();
      const log = await storage.getDailyLog(today);
      
      // Get already sent notifications (cast from JSONB)
      const sentNotifications = (log?.notificationsSent as number[]) || [];
      const currentPercent = metrics.pacingPercent;
      const thresholds = [25, 50, 75, 100];

      for (const t of thresholds) {
        // If we crossed a threshold we haven't sent yet...
        if (currentPercent >= t && !sentNotifications.includes(t)) {
            // Fire and forget (don't await to keep UI fast)
            sendWifeAlert(t, metrics.movesCompleted).catch(console.error);
            
            // Mark as sent
            const newSent = [...sentNotifications, t];
            await storage.updateDailyLog(today, { notificationsSent: newSent });
        }
      }
      
      res.json(move);
    } catch (error) {
      console.error("Error completing move:", error);
      res.status(500).json({ error: "Failed to complete move" });
    }
  });

  app.post("/api/moves/:id/promote", async (req, res) => {
    try {
      const id = parseInt(req.params.id);
      const move = await storage.promoteMove(id);
      if (!move) {
        res.status(404).json({ error: "Move not found" });
        return;
      }
      res.json(move);
    } catch (error) {
      console.error("Error promoting move:", error);
      res.status(500).json({ error: "Failed to promote move" });
    }
  });

  app.post("/api/moves/:id/demote", async (req, res) => {
    try {
      const id = parseInt(req.params.id);
      const move = await storage.demoteMove(id);
      if (!move) {
        res.status(404).json({ error: "Move not found" });
        return;
      }
      res.json(move);
    } catch (error) {
      console.error("Error demoting move:", error);
      res.status(500).json({ error: "Failed to demote move" });
    }
  });

  app.delete("/api/moves/:id", async (req, res) => {
    try {
      const id = parseInt(req.params.id);
      await storage.deleteMove(id);
      res.status(204).send();
    } catch (error) {
      console.error("Error deleting move:", error);
      res.status(500).json({ error: "Failed to delete move" });
    }
  });

  app.post("/api/moves/reorder", async (req, res) => {
    try {
      const { status, orderedIds } = req.body;
      if (!status || !Array.isArray(orderedIds)) {
        res.status(400).json({ error: "status and orderedIds are required" });
        return;
      }
      await storage.reorderMoves(status as MoveStatus, orderedIds);
      res.json({ success: true });
    } catch (error) {
      console.error("Error reordering moves:", error);
      res.status(500).json({ error: "Failed to reorder moves" });
    }
  });

  app.get("/api/triage", async (req, res) => {
    try {
      const result = await runTriage();
      res.json(result);
    } catch (error) {
      console.error("Error running triage:", error);
      res.status(500).json({ error: "Failed to run triage" });
    }
  });

  app.post("/api/triage/auto-fix", async (req, res) => {
    try {
      const result = await runTriageWithAutoRemediation();
      res.json(result);
    } catch (error) {
      console.error("Error running triage with auto-fix:", error);
      res.status(500).json({ error: "Failed to run triage with auto-fix" });
    }
  });

  const httpServer = createServer(app);

  return httpServer;
}

}

