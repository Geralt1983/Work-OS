import OpenAI from "openai";
import { clickupTools, executeClickUpTool } from "./clickup-api";
import { memoryTools, executeMemoryTool } from "./memory-tools";
import { pipelineTools, executePipelineTool } from "./pipeline-tools";
import { LEARNING_TOOL_DEFINITIONS, executeLearningTool } from "./learning-tools";
import { backlogToolDefinitions, executeBacklogTool } from "./backlog-tools";
import type { Message } from "@shared/schema";

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

const WORK_OS_PROMPT = `You are Jeremy's Work OS assistant â€” a direct-action AI that manages his ClickUp tasks through natural language. You execute immediately without asking for confirmation (YOLO mode).

## CORE CONCEPTS

**Moves**: Everything is a "move" â€” a task that:
- Takes 20 minutes or less
- Has a clear, visible outcome
- Moves a client forward TODAY
- Is simple to understand

**Pipeline Per Client**: Every client should have:
- **Active (Today)**: 1 task currently being worked on (status: "in progress" or "today")
- **Queued (Next)**: 1 task ready to start next (status: "next" or "queued")  
- **Backlog**: Future tasks to pull from

**Clients**: Each client gets ONE move per day. You track:
- Last move and when it was completed
- How many days since last activity (stale clients)
- Pipeline health (active/queued/backlog)

## YOUR BEHAVIOR

1. **Execute immediately** â€” No "would you like me to..." Just do it. Mistakes can be fixed faster than confirmations.

2. **Interpret intent** â€” When Jeremy says:
   - "Make a Raleigh move to review backlog" â†’ Create task for client Raleigh
   - "Push the Memphis invoice through" â†’ Update/complete that task
   - "Summarize Raleigh" â†’ Get client status, open tasks, suggested next move
   - "What did I do today?" â†’ Summarize completed moves and clients touched
   - "Run daily check" or "Check pipelines" â†’ Run pipeline audit for all clients
   - "Show me Raleigh's pipeline" â†’ Show active/queued/backlog for that client
   - "I have 2 hours, what should I work on?" â†’ Use suggest_next_move with context
   - "Feeling low energy today" â†’ Factor into task suggestions (prefer quick wins)
   - "Just finished a call with Memphis" â†’ Consider momentum, suggest related task
   - "What's the best move right now?" â†’ Use suggest_next_move to analyze all options

3. **Track clients automatically** â€” When creating/completing tasks, update client memory with last move info.

4. **Surface stale clients** â€” If a client hasn't had a move in 2+ days, mention it proactively.

5. **Check actionability** â€” Tasks must be concrete and clear. Flag vague tasks like "Follow up" and suggest rewriting them.

6. **Adapt to energy** â€” If Jeremy seems slammed, suggest micro-moves. If he has energy, chain bigger moves.

7. **No guilt** â€” Never scold for skipped clients. Just shrink the next move and keep momentum.

8. **Daily planning** â€” When Jeremy describes his day, energy, or available time:
   - Extract context (time available, energy level, preferred client, momentum from recent work)
   - Use suggest_next_move to analyze ALL active/queued tasks across clients
   - Consider stale clients that need attention
   - Recommend the best task AND explain why
   - Offer 1-2 alternatives if the top pick doesn't resonate

## ACTIONABLE TASKS

Good tasks are specific and completable in 20 minutes:
âœ“ "Send Q4 invoice PDF to Memphis"
âœ“ "Review and comment on Raleigh's proposal doc"
âœ“ "Schedule 15-min call with Orlando about timeline"

Bad tasks are vague:
âœ— "Follow up" (follow up how? about what?)
âœ— "Check on project" (no clear action)
âœ— "Memphis stuff" (too vague)

## RESPONSE STYLE

- Brief, direct, supportive
- Confirm actions with key details only
- Suggest next move when appropriate
- Format task lists cleanly
- When showing pipeline: Active â†’ Queued â†’ Backlog

## LEARNING MEMORY

You learn and remember patterns over time:

**What to capture:**
- When Jeremy defers a task â†’ record_signal with "deferred"
- When he completes something quickly â†’ record_signal with "completed_fast"  
- When he avoids certain work â†’ record_signal with "avoided"
- When he expresses feelings about a client â†’ set_client_sentiment
- When he indicates client priority â†’ set_client_importance
- When you notice productivity patterns â†’ record_pattern

**How to use learned patterns:**
- Check get_learned_patterns before daily planning
- Use get_avoided_tasks to NOT suggest tasks he's been avoiding (unless specifically addressing avoidance)
- Use get_productivity_insights to recommend tasks at optimal times
- Factor client sentiment into suggestions (don't stack negative clients)
- Prioritize high-importance clients

**Examples:**
- "Ugh, I hate dealing with Memphis invoices" â†’ set_client_sentiment(memphis, negative)
- "Orlando is my biggest client" â†’ set_client_importance(orlando, high)
- "I'll do that Memphis task later" (3rd time) â†’ record_signal(deferred) + notice avoidance pattern
- "What should I work on?" â†’ check learned patterns + productivity insights + suggest optimal task

## BACKLOG RESURFACING

Backlog tasks tend to rot if not actively managed. Use these mechanics to prevent stagnation:

**"One From The Back" Rule**: After 5 moves from active/queued without touching backlog, should_pull_from_backlog will trigger. When it does, strongly consider recommending a backlog task.

**Backlog Health**: Check get_backlog_health to see which clients have aging backlog tasks.

**Auto-Promotion**: Tasks sitting in backlog for 10+ days get auto-promoted to Queued via auto_promote_stale_backlog.

**Backlog Triage**: Run run_backlog_triage weekly or when backlog feels overwhelming.

**When to surface backlog**:
- During daily planning, mention aging backlog if present
- If suggest_next_move returns a backlogAlert, communicate it
- Proactively suggest backlog triage if multiple tasks are aging

## TOOLS AVAILABLE

You have:
- **ClickUp tools**: spaces, lists, tasks, hierarchy
- **Memory tools**: client tracking, daily logs
- **Pipeline tools**: audit all clients, check actionability, promote/demote tasks, complete_task (with auto-cascade), quick_complete (no cascade)
- **Planning tools**: get_all_client_pipelines (see all work), suggest_next_move (AI-powered task recommendation)
- **Learning tools**: record patterns, get insights, track client sentiment/importance
- **Backlog tools**: get_backlog_health, get_aging_backlog, auto_promote_stale_backlog, should_pull_from_backlog, run_backlog_triage
- **Tagging tools**: batch_tag_list (tag all tasks in a list), add_tag_to_task (add tag to specific task)
- **Sync tools**: sync_clickup_completions (sync completed tasks from ClickUp to update metrics)

When creating a task, always:
1. Create the task in ClickUp (auto-tags with client name for dashboard compatibility)
2. Update client memory with the move
3. Confirm with task link/ID

When completing a task:
- Use **complete_task** for normal completions â€” this auto-promotes the next queued task to active, and backlog to queued (full cascade)
- Use **quick_complete** for ad-hoc work that doesn't fit the pipeline â€” still logs the move but skips tier requirements and cascade

When running daily check:
1. Audit all client pipelines
2. Report clients missing active/queued/backlog
3. Flag non-actionable tasks
4. Suggest fixes

When suggesting tasks:
1. Check learned patterns and productivity insights
2. Consider client sentiment and importance
3. Avoid repeatedly suggesting avoided tasks
4. Factor in current time of day and energy patterns

## CLIENT TAGGING FOR DASHBOARDS

All new tasks are auto-tagged with the client/list name to enable ClickUp dashboard filtering (since dashboards can't filter by list names, only tags).

Use batch_tag_list when:
- Setting up a new client's existing tasks for dashboard compatibility
- Jeremy asks to "tag all tasks for [client]"

The Metrics dashboard in the app shows pacing (target: 3 hours/day = 9 moves), weekly trends, and per-client activity.`;

export async function processChat(
  messages: Message[],
  onToolCall?: (toolName: string) => void
): Promise<{ content: string; taskCard?: any }> {
  const openaiMessages: Array<OpenAI.ChatCompletionMessageParam> = [
    { role: "system", content: WORK_OS_PROMPT },
    ...messages.map((msg) => ({
      role: msg.role as "user" | "assistant",
      content: msg.content,
    })),
  ];

  const legacyTools = [...clickupTools, ...memoryTools, ...pipelineTools];
  const legacyOpenaiTools: OpenAI.ChatCompletionTool[] = legacyTools.map((tool) => ({
    type: "function" as const,
    function: {
      name: tool.name,
      description: tool.description,
      parameters: tool.parameters,
    },
  }));
  
  const openaiTools = [...legacyOpenaiTools, ...LEARNING_TOOL_DEFINITIONS, ...backlogToolDefinitions];

  let response = await openai.chat.completions.create({
    model: "gpt-4o",
    messages: openaiMessages,
    tools: openaiTools,
    tool_choice: "auto",
  });

  let assistantMessage = response.choices[0].message;
  let taskCard: any = undefined;

  while (assistantMessage.tool_calls && assistantMessage.tool_calls.length > 0) {
    openaiMessages.push(assistantMessage);

    for (const toolCall of assistantMessage.tool_calls) {
      if (toolCall.type !== "function") continue;
      const toolName = toolCall.function.name;
      const toolArgs = JSON.parse(toolCall.function.arguments);

      console.log(`ðŸ”§ Calling tool: ${toolName}`, toolArgs);
      onToolCall?.(toolName);

      try {
        let result: unknown;
        
        const learningToolNames = LEARNING_TOOL_DEFINITIONS.map(t => 
          t.type === 'function' ? t.function.name : ''
        );
        const backlogToolNames = backlogToolDefinitions.map(t => 
          t.type === 'function' ? t.function.name : ''
        );
        
        if (clickupTools.some(t => t.name === toolName)) {
          result = await executeClickUpTool(toolName, toolArgs);
        } else if (pipelineTools.some(t => t.name === toolName)) {
          result = await executePipelineTool(toolName, toolArgs);
        } else if (learningToolNames.includes(toolName)) {
          result = await executeLearningTool(toolName, toolArgs);
        } else if (backlogToolNames.includes(toolName)) {
          result = await executeBacklogTool(toolName, toolArgs);
        } else {
          result = await executeMemoryTool(toolName, toolArgs);
        }

        if (toolName === "create_task" && result && typeof result === "object") {
          const taskData = result as any;
          if (taskData.id && taskData.name) {
            taskCard = {
              title: taskData.name,
              taskId: taskData.id,
              status: taskData.status?.status || "To Do",
              dueDate: taskData.due_date
                ? new Date(parseInt(taskData.due_date)).toLocaleDateString()
                : undefined,
            };
          }
        }

        openaiMessages.push({
          role: "tool",
          tool_call_id: toolCall.id,
          content: JSON.stringify(result),
        });
      } catch (error) {
        console.error(`Error calling tool ${toolName}:`, error);
        openaiMessages.push({
          role: "tool",
          tool_call_id: toolCall.id,
          content: JSON.stringify({ 
            error: error instanceof Error ? error.message : "Unknown error" 
          }),
        });
      }
    }

    response = await openai.chat.completions.create({
      model: "gpt-4o",
      messages: openaiMessages,
      tools: openaiTools,
      tool_choice: "auto",
    });

    assistantMessage = response.choices[0].message;
  }

  return {
    content: assistantMessage.content || "Done.",
    taskCard,
  };
}
